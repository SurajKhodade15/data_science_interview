{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e14b65",
   "metadata": {},
   "source": [
    "# ðŸ“˜ LangChain â€” Retrievers and Chains\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Executive Summary**\n",
    "- **Retrievers:** Components that fetch relevant documents or knowledge chunks from a database/vector store based on a query.  \n",
    "- **Chains:** Pipelines that define a sequence of steps, combining LLMs, prompts, memory, and tools to produce structured output.  \n",
    "- **Why important:** They allow **multi-step reasoning, RAG workflows, and structured GenAI applications**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Retrievers**\n",
    "\n",
    "| Component | Description | Example | Notes |\n",
    "|-----------|------------|--------|-------|\n",
    "| **Vector Retriever** | Retrieves top-k documents using vector similarity | FAISS, Pinecone, Chroma | Embeddings â†’ similarity search |\n",
    "| **Keyword Retriever** | Retrieves docs based on keyword matching | Simple text search | Good for small datasets or metadata filtering |\n",
    "| **Time/Date Retriever** | Filters by timestamp | Logs, versioned documents | Combine with vector retrieval for hybrid search |\n",
    "| **Custom Retriever** | User-defined retrieval logic | API calls, business rules | Flexible for domain-specific needs |\n",
    "\n",
    "**Notes:**  \n",
    "- Often paired with **Embedding models** for semantic similarity.  \n",
    "- Retrieval quality directly impacts RAG or chain outputs.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Chains**\n",
    "\n",
    "| Type | Description | Example Use Case | Notes |\n",
    "|------|------------|----------------|------|\n",
    "| **LLMChain** | Single LLM + PromptTemplate | Explain a concept | Simplest pipeline |\n",
    "| **SequentialChain** | Multiple LLMChains executed in sequence | Summarize â†’ Translate â†’ Format | Maintains output between steps |\n",
    "| **SimpleSequentialChain** | SequentialChain without input/output mapping | Quick multi-step tasks | Lightweight version |\n",
    "| **RetrievalQA Chain** | LLM + Retriever | Answer questions from documents | Core of RAG workflows |\n",
    "| **StuffingChain** | Combines all retrieved docs into one prompt | Small context window LLMs | Simple, can exceed token limit |\n",
    "| **Map-Reduce Chain** | Processes chunks individually â†’ combines results | Summarization of long docs | Efficient for large datasets |\n",
    "| **Refine Chain** | Iteratively improves output with new info | Long-form answers, summaries | Handles large context gracefully |\n",
    "| **Custom Chains** | User-defined sequences | Multi-step workflows with agents/tools | Flexible for enterprise apps |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Practical Usage Patterns**\n",
    "\n",
    "| Pattern | Components | Notes |\n",
    "|---------|-----------|------|\n",
    "| RAG | Retriever + RetrievalQA Chain | LLM grounded in external knowledge |\n",
    "| Multi-step processing | SequentialChain or Map-Reduce Chain | Summarize â†’ Answer â†’ Format |\n",
    "| Chatbot with context | LLMChain + Memory | Maintains conversational history |\n",
    "| Domain QA | Retriever + Refine Chain | Iteratively improves factual accuracy |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Python Examples**\n",
    "\n",
    "### 5.1 Retrieval Example\n",
    "\n",
    "```python\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load documents\n",
    "loader = PyPDFLoader(\"sample_doc.pdf\")\n",
    "docs = loader.load_and_split()\n",
    "\n",
    "# Create embeddings + vector DB\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Simple retrieval\n",
    "query = \"Explain LangChain architecture\"\n",
    "retrieved_docs = vector_db.similarity_search(query, k=3)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Doc {i+1}:\", doc.page_content[:200], \"...\\n\")\n",
    "````\n",
    "\n",
    "### 5.2 LLMChain Example\n",
    "\n",
    "```python\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain {topic} in simple terms.\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run(\"LangChain Retrievers and Chains\")\n",
    "print(output)\n",
    "```\n",
    "\n",
    "### 5.3 RetrievalQA Chain Example\n",
    "\n",
    "```python\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3}),\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "result = qa_chain.run(\"Key concepts of LangChain RAG workflow\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **Best Practices**\n",
    "\n",
    "* **Retriever Tips:**\n",
    "\n",
    "  * Use semantic embeddings for relevance, not just keyword match.\n",
    "  * Consider hybrid retrieval: semantic + metadata filtering.\n",
    "* **Chain Tips:**\n",
    "\n",
    "  * Use Map-Reduce for large documents to avoid token overflow.\n",
    "  * Refine chains improve factual accuracy iteratively.\n",
    "  * Modularize chains for reusability and testing.\n",
    "* **Integration:**\n",
    "\n",
    "  * Combine retrievers + chains + memory for multi-turn, grounded GenAI apps.\n",
    "  * Always monitor token usage and latency for cost management.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… *Quick Review*:\n",
    "\n",
    "* **Retriever = fetch relevant knowledge**\n",
    "* **Chain = structured sequence of LLM + prompts + tools**\n",
    "* Core for **RAG, multi-step reasoning, and chatbots** in LangChain.\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b4ad0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
