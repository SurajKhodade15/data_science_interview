{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9cd8f5",
   "metadata": {},
   "source": [
    "\n",
    "# üìò Introduction to LangChain for GenAI\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Theory**\n",
    "\n",
    "* **LangChain** is an open-source framework designed to **orchestrate and enhance LLM (Large Language Model) applications**.\n",
    "* It simplifies **integration of LLMs** with external systems such as databases, APIs, knowledge bases, and tools.\n",
    "* It provides **modularity** (components like prompts, chains, memory, agents) and **scalability** for building production-ready GenAI apps.\n",
    "* **Why LangChain?**\n",
    "\n",
    "  * LLMs alone are limited (context length, reasoning, factuality).\n",
    "  * LangChain adds **structure + reasoning** by chaining prompts and connecting with external data.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Core Components**\n",
    "\n",
    "| Component                         | Description                                         | Example Use Case                          |\n",
    "| --------------------------------- | --------------------------------------------------- | ----------------------------------------- |\n",
    "| **Prompt Templates**              | Standardize and manage dynamic prompts              | Query rephrasing, structured task prompts |\n",
    "| **Chains**                        | Sequence of LLM + tools (multi-step reasoning)      | Summarize ‚Üí Translate ‚Üí Answer            |\n",
    "| **Memory**                        | Store conversation context                          | Chatbots that remember history            |\n",
    "| **Agents**                        | LLMs that decide dynamically which tool to use      | AI assistants querying DB, APIs           |\n",
    "| **Tools**                         | External utilities (DB, Google search, Python REPL) | Knowledge augmentation                    |\n",
    "| **Document Loaders & Retrievers** | Load and retrieve knowledge from docs               | RAG (Retrieval-Augmented Generation)      |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Usage in GenAI**\n",
    "\n",
    "* **Chatbots**: Personalized conversational AI with memory.\n",
    "* **Retrieval-Augmented Generation (RAG)**: Query company data, PDFs, or vector DBs.\n",
    "* **Multi-step Workflows**: e.g., research assistants ‚Üí search ‚Üí analyze ‚Üí summarize.\n",
    "* **Agents**: Automating decision-making (AI ‚Äúexecuting‚Äù tasks using tools).\n",
    "* **Enterprise Apps**: Connecting LLMs to CRM, ERP, or analytics pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Interview Questions & Answers**\n",
    "\n",
    "| Question                                                  | Answer                                                                                                                                                                                                                                                             |\n",
    "| --------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **Q1. What is LangChain and why is it needed?**           | LangChain is a framework to build applications powered by LLMs, allowing chaining of tasks, integration with external data sources, and tool usage. It is needed to overcome LLM limitations like hallucination, lack of context memory, and restricted reasoning. |\n",
    "| **Q2. What are Chains in LangChain?**                     | Chains are sequences of calls (LLM + other components) where the output of one step feeds into the next.                                                                                                                                                           |\n",
    "| **Q3. How does LangChain handle memory?**                 | Memory modules preserve conversation history or contextual info across multiple calls to the LLM.                                                                                                                                                                  |\n",
    "| **Q4. What is the difference between Chains and Agents?** | Chains follow predefined steps, while Agents dynamically decide actions (tools to use, sequence of steps) at runtime.                                                                                                                                              |\n",
    "| **Q5. How is LangChain used in RAG?**                     | LangChain connects to vector databases (e.g., Pinecone, FAISS) to retrieve relevant chunks of knowledge and feed them into the LLM prompt.                                                                                                                         |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Python Example**\n",
    "\n",
    "```python\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "# Create a Prompt Template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain {topic} in simple terms for a beginner.\"\n",
    ")\n",
    "\n",
    "# Build Chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run Chain\n",
    "response = chain.run(\"LangChain\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **Additional Notes**\n",
    "\n",
    "* Works seamlessly with **OpenAI, Hugging Face, Cohere, Anthropic** models.\n",
    "* Integrates with **Vector DBs** like Pinecone, FAISS, Weaviate.\n",
    "* Ideal for building **scalable production-level GenAI applications**.\n",
    "* **Alternatives**: LlamaIndex, Haystack.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ *Quick Review*: LangChain = **\"LLM + memory + tools + chains + agents\"** ‚Üí makes LLMs more **useful, reliable, and production-ready**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b797342e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
