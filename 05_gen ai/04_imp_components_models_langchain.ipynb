{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99a42c9",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“˜ LangChain â€” Important Components and Models\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Theory**\n",
    "\n",
    "LangChain is modular; it has **key components** and **model integrations** that enable GenAI applications to be reliable, composable, and scalable.\n",
    "\n",
    "* **Components** handle the workflow: prompts, memory, chains, agents, tools, document loaders.\n",
    "* **Models** are the underlying LLMs or embedding models used for reasoning, generation, and retrieval.\n",
    "* Together, they allow **multi-step reasoning**, **context retention**, and **integration with external knowledge sources**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Key Components**\n",
    "\n",
    "| Component           | Purpose                       | Usage Example                             | Notes                                    |\n",
    "| ------------------- | ----------------------------- | ----------------------------------------- | ---------------------------------------- |\n",
    "| **PromptTemplate**  | Standardizes input prompts    | Dynamic templates for Q\\&A, summarization | Handles variables, formatting            |\n",
    "| **LLMChain**        | Single LLM + Prompt pipeline  | Generate a paragraph given a topic        | Simplest form of chain                   |\n",
    "| **SequentialChain** | Multi-step chained LLM calls  | Summarize â†’ Translate â†’ Format            | Maintains output from one chain to next  |\n",
    "| **Memory**          | Tracks state or context       | Chatbots with conversation memory         | Types: ConversationBuffer, SummaryMemory |\n",
    "| **Agent**           | Dynamically decides actions   | AI assistant querying tools or APIs       | Can use reasoning loops, tool selection  |\n",
    "| **Tool**            | External utility              | Search API, Python REPL, Calculator       | Used by agents for execution             |\n",
    "| **Retriever**       | Fetches relevant docs         | FAISS/Pinecone vector search              | Key for RAG workflows                    |\n",
    "| **DocumentLoader**  | Loads knowledge into pipeline | PDF, CSV, HTML, web scraping              | Supports preprocessing & chunking        |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Important Models in LangChain**\n",
    "\n",
    "| Model Type                 | Examples                                                     | Purpose                                  | Notes                                                 |\n",
    "| -------------------------- | ------------------------------------------------------------ | ---------------------------------------- | ----------------------------------------------------- |\n",
    "| **LLMs (Text Generation)** | OpenAI GPT-3/4, LLaMA, Mistral, Anthropic Claude             | Generate text, answer questions, code    | Can be decoder-only, supports chain + agent workflows |\n",
    "| **Embedding Models**       | OpenAI Embeddings, HuggingFace Sentence Transformers, Cohere | Vectorize text for semantic search       | Used with retrievers/vector DBs                       |\n",
    "| **Chat Models**            | ChatOpenAI, ChatAnthropic                                    | Multi-turn conversational applications   | Supports memory integration                           |\n",
    "| **Specialized Models**     | Code models (Codex, StarCoder), Multimodal (GPT-4V)          | Domain-specific or multimodal generation | Integrated via LangChain Chains or Agents             |\n",
    "| **Local/Open-source LLMs** | LLaMA, Mistral, Falcon                                       | On-prem or cost-effective solutions      | Allows full control, fine-tuning, privacy             |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Practical Usage Patterns**\n",
    "\n",
    "| Component/Model                   | Typical Workflow               | Example Use Case                                    |\n",
    "| --------------------------------- | ------------------------------ | --------------------------------------------------- |\n",
    "| LLMChain + PromptTemplate         | Single-step generation         | Explain a concept, generate content                 |\n",
    "| SequentialChain + Memory          | Multi-step reasoning           | Research assistant: summarize â†’ analyze â†’ answer    |\n",
    "| Agent + Tool + LLM                | Decision-making with execution | AI assistant querying DB, doing calculations        |\n",
    "| Retriever + Embedding Model + LLM | Retrieval-augmented generation | Answer questions from documents/PDFs/knowledge base |\n",
    "| Chat Model + Memory               | Conversational AI              | Customer support chatbot with context               |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **Python Example â€” Components + Models**\n",
    "\n",
    "```python\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "# 1) LLM\n",
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "# 2) Prompt Template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer the question concisely: {question}\"\n",
    ")\n",
    "\n",
    "# 3) Memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\")\n",
    "\n",
    "# 4) LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "# Run chain\n",
    "response = chain.run(\"What is LangChain?\")\n",
    "print(response)\n",
    "\n",
    "# 5) Define Tool\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Simple Calculator\",\n",
    "        func=lambda x: eval(x),\n",
    "        description=\"Performs simple math calculations\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# 6) Initialize Agent\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "agent.run(\"Calculate 15 * 12\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. **Additional Intelligence & Best Practices**\n",
    "\n",
    "* **Heuristics:**\n",
    "\n",
    "  * Use `LLMChain` for simple tasks, `SequentialChain` for multi-step reasoning, `Agent` for dynamic tool usage.\n",
    "  * Always pair embeddings + retriever for RAG applications.\n",
    "\n",
    "* **Scaling:**\n",
    "\n",
    "  * Modularize components, reuse prompt templates.\n",
    "  * Integrate caching to reduce LLM calls and cost.\n",
    "\n",
    "* **Safety & Monitoring:**\n",
    "\n",
    "  * Track prompt history and output.\n",
    "  * Add guardrails in tools and agents to prevent unsafe operations.\n",
    "\n",
    "* **Memory Tips:**\n",
    "\n",
    "  * `ConversationBufferMemory` â†’ keeps full chat history.\n",
    "  * `ConversationSummaryMemory` â†’ keeps summary to reduce token usage.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… *Quick Review*: LangChain = **PromptTemplates + Chains + Memory + Agents + Tools + Models** â†’ modular and composable for **robust GenAI applications**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ffa43e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
