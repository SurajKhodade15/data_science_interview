{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1328ec94",
   "metadata": {},
   "source": [
    "\n",
    "# **Named Entity Recognition (NER)**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Theory**\n",
    "\n",
    "### **What is NER?**\n",
    "\n",
    "* **Definition**: Named Entity Recognition (NER) is the process of identifying and classifying **entities** in text into predefined categories.\n",
    "\n",
    "* Common categories:\n",
    "\n",
    "  * **PERSON** → People (e.g., “Albert Einstein”)\n",
    "  * **ORG** → Organizations (e.g., “Google”)\n",
    "  * **GPE** → Geopolitical Entities (countries, cities, states)\n",
    "  * **DATE / TIME** → Temporal expressions\n",
    "  * **MONEY / PERCENT / CARDINAL / PRODUCT / EVENT**, etc.\n",
    "\n",
    "* Example:\n",
    "  Text: *“Apple was founded by Steve Jobs in California in 1976.”*\n",
    "  NER Output:\n",
    "\n",
    "  ```\n",
    "  Apple → ORG\n",
    "  Steve Jobs → PERSON\n",
    "  California → GPE\n",
    "  1976 → DATE\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Why is NER important?**\n",
    "\n",
    "* **Information extraction**: Identify key facts from unstructured text.\n",
    "* **Knowledge graphs**: Build connections between entities.\n",
    "* **Chatbots and question answering**: Recognize entities to respond intelligently.\n",
    "* **Search and retrieval**: Improve indexing and relevance.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Examples**\n",
    "\n",
    "### **NER with SpaCy**\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"Apple was founded by Steve Jobs in California in 1976.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print entities with labels\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"→\", ent.label_)\n",
    "\n",
    "# Visualization\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Apple → ORG\n",
    "Steve Jobs → PERSON\n",
    "California → GPE\n",
    "1976 → DATE\n",
    "```\n",
    "\n",
    "* Visualization highlights entities with different colors for each label.\n",
    "\n",
    "---\n",
    "\n",
    "### **NER with NLTK (Using Pre-trained Chunking)**\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"maxent_ne_chunker\")\n",
    "nltk.download(\"words\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "sentence = \"Apple was founded by Steve Jobs in California in 1976.\"\n",
    "tokens = word_tokenize(sentence)\n",
    "pos_tags = pos_tag(tokens)\n",
    "ner_tree = ne_chunk(pos_tags)\n",
    "\n",
    "print(ner_tree)\n",
    "```\n",
    "\n",
    "**Output (Tree Structure):**\n",
    "\n",
    "```\n",
    "(S\n",
    "  (ORGANIZATION Apple/NNP)\n",
    "  was/VBD\n",
    "  founded/VBN\n",
    "  by/IN\n",
    "  (PERSON Steve/NNP Jobs/NNP)\n",
    "  in/IN\n",
    "  (GPE California/NNP)\n",
    "  in/IN\n",
    "  1976/CD\n",
    "  ./.)\n",
    "```\n",
    "\n",
    "> Note: NLTK’s NER is rule/statistics-based and less accurate than SpaCy for modern applications.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Interview-Style Q&A**\n",
    "\n",
    "### **Basic Level**\n",
    "\n",
    "**Q1. What is Named Entity Recognition (NER)?**\n",
    "*A: NER is the task of identifying and classifying entities in text into predefined categories like PERSON, ORG, GPE, DATE, etc.*\n",
    "\n",
    "**Q2. Give an example of NER.**\n",
    "*A: In “Apple was founded by Steve Jobs in California in 1976”: Apple → ORG, Steve Jobs → PERSON, California → GPE, 1976 → DATE.*\n",
    "\n",
    "---\n",
    "\n",
    "### **Intermediate Level**\n",
    "\n",
    "**Q3. How does SpaCy perform NER?**\n",
    "*A: SpaCy uses pre-trained statistical models based on neural networks. It predicts entities with labels for each token span and is optimized for speed and production use.*\n",
    "\n",
    "**Q4. Difference between NER in NLTK and SpaCy?**\n",
    "*A: NLTK relies on rule-based and classical statistical chunking models, less accurate and slower. SpaCy uses neural network models, faster and more accurate, with visualizations built-in.*\n",
    "\n",
    "---\n",
    "\n",
    "### **Advanced Level**\n",
    "\n",
    "**Q5. How do Transformer-based models handle NER?**\n",
    "*A: Transformer models (like BERT) treat NER as a **token classification task**, leveraging contextual embeddings to identify entity spans more accurately than rule-based or classical models.*\n",
    "\n",
    "**Q6. What are some challenges in NER?**\n",
    "*A: Ambiguity (“Apple” as fruit vs company), overlapping entities, domain adaptation (legal, medical), multilingual texts, and nested entities.*\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Visualization in SpaCy**\n",
    "\n",
    "* `displacy.render(doc, style=\"ent\")` highlights entities with **different colors**:\n",
    "\n",
    "  * ORG → Blue\n",
    "  * PERSON → Green\n",
    "  * GPE → Orange\n",
    "  * DATE → Red\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b04f6bc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
