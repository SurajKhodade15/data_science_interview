{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f5bf902",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Hyperparameter Tuning in Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "### **Definition**\n",
    "\n",
    "* **Hyperparameters**: Parameters set **before training** (not learned from data).\n",
    "  Example: learning rate, number of trees in Random Forest, depth of a neural network.\n",
    "* **Hyperparameter Tuning**: The process of finding the **optimal set of hyperparameters** that maximize model performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Common Hyperparameter Tuning Methods**\n",
    "\n",
    "### **1. Grid Search**\n",
    "\n",
    "* **Definition:** Exhaustively tries all combinations from a predefined hyperparameter grid.\n",
    "* **Pros:** Simple, guarantees best within grid.\n",
    "* **Cons:** Computationally expensive.\n",
    "* **Use Case:** Small search space.\n",
    "\n",
    "ðŸ‘‰ **Python Example:**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, None]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Random Search**\n",
    "\n",
    "* **Definition:** Randomly selects combinations from the parameter grid.\n",
    "* **Pros:** Faster, good for large search space.\n",
    "* **Cons:** May miss optimal parameters.\n",
    "* **Use Case:** High-dimensional hyperparameter spaces.\n",
    "\n",
    "ðŸ‘‰ **Python Example:**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_depth': randint(2, 10)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_dist, cv=5, n_iter=10, scoring='accuracy')\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(\"Best Params:\", random_search.best_params_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Bayesian Optimization**\n",
    "\n",
    "* **Definition:** Uses past evaluation results to model the objective function and choose the next set of hyperparameters intelligently.\n",
    "* **Pros:** More sample-efficient than random/grid search.\n",
    "* **Cons:** More complex.\n",
    "* **Tools:** `hyperopt`, `scikit-optimize`, `Optuna`.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Evolutionary Algorithms (Genetic Search)**\n",
    "\n",
    "* **Definition:** Hyperparameters are optimized using evolutionary strategies (mutation, crossover).\n",
    "* **Use Case:** Neural architecture search, complex ML pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Automated ML (AutoML)**\n",
    "\n",
    "* **Definition:** Automated frameworks that optimize hyperparameters + models simultaneously.\n",
    "* **Examples:** Google AutoML, Auto-sklearn, H2O.ai.\n",
    "\n",
    "---\n",
    "\n",
    "## **Interview-Style Q\\&A**\n",
    "\n",
    "**Q1:** Whatâ€™s the difference between parameters and hyperparameters?\n",
    "ðŸ‘‰ Parameters are learned from data (weights in linear regression, neural network). Hyperparameters are set before training (learning rate, depth, regularization strength).\n",
    "\n",
    "**Q2:** When would you use Random Search over Grid Search?\n",
    "ðŸ‘‰ When the search space is large. Random Search often finds near-optimal solutions much faster.\n",
    "\n",
    "**Q3:** What is the role of cross-validation in hyperparameter tuning?\n",
    "ðŸ‘‰ It ensures the hyperparameters generalize across folds, avoiding overfitting to a single split.\n",
    "\n",
    "**Q4:** Why is Bayesian Optimization preferred in deep learning?\n",
    "ðŸ‘‰ Because it intelligently balances exploration (trying new hyperparameters) and exploitation (refining good ones), reducing training runs.\n",
    "\n",
    "**Q5:** What pitfalls should be avoided in hyperparameter tuning?\n",
    "ðŸ‘‰\n",
    "\n",
    "* Using the test set for tuning (leads to data leakage).\n",
    "* Very large search grids without constraints.\n",
    "* Not fixing random seeds â†’ reproducibility issues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79473af9",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸŽ¯ Hyperparameter Tuning in Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "### **Definition**\n",
    "\n",
    "* **Hyperparameters**: Parameters set **before training** (not learned from data).\n",
    "  Example: learning rate, number of trees in Random Forest, depth of a neural network.\n",
    "* **Hyperparameter Tuning**: The process of finding the **optimal set of hyperparameters** that maximize model performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Common Hyperparameter Tuning Methods**\n",
    "\n",
    "### **1. Grid Search**\n",
    "\n",
    "* **Definition:** Exhaustively tries all combinations from a predefined hyperparameter grid.\n",
    "* **Pros:** Simple, guarantees best within grid.\n",
    "* **Cons:** Computationally expensive.\n",
    "* **Use Case:** Small search space.\n",
    "\n",
    "ðŸ‘‰ **Python Example:**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, None]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Random Search**\n",
    "\n",
    "* **Definition:** Randomly selects combinations from the parameter grid.\n",
    "* **Pros:** Faster, good for large search space.\n",
    "* **Cons:** May miss optimal parameters.\n",
    "* **Use Case:** High-dimensional hyperparameter spaces.\n",
    "\n",
    "ðŸ‘‰ **Python Example:**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_depth': randint(2, 10)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_dist, cv=5, n_iter=10, scoring='accuracy')\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(\"Best Params:\", random_search.best_params_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Bayesian Optimization**\n",
    "\n",
    "* **Definition:** Uses past evaluation results to model the objective function and choose the next set of hyperparameters intelligently.\n",
    "* **Pros:** More sample-efficient than random/grid search.\n",
    "* **Cons:** More complex.\n",
    "* **Tools:** `hyperopt`, `scikit-optimize`, `Optuna`.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Evolutionary Algorithms (Genetic Search)**\n",
    "\n",
    "* **Definition:** Hyperparameters are optimized using evolutionary strategies (mutation, crossover).\n",
    "* **Use Case:** Neural architecture search, complex ML pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Automated ML (AutoML)**\n",
    "\n",
    "* **Definition:** Automated frameworks that optimize hyperparameters + models simultaneously.\n",
    "* **Examples:** Google AutoML, Auto-sklearn, H2O.ai.\n",
    "\n",
    "---\n",
    "\n",
    "## **Interview-Style Q\\&A**\n",
    "\n",
    "**Q1:** Whatâ€™s the difference between parameters and hyperparameters?\n",
    "ðŸ‘‰ Parameters are learned from data (weights in linear regression, neural network). Hyperparameters are set before training (learning rate, depth, regularization strength).\n",
    "\n",
    "**Q2:** When would you use Random Search over Grid Search?\n",
    "ðŸ‘‰ When the search space is large. Random Search often finds near-optimal solutions much faster.\n",
    "\n",
    "**Q3:** What is the role of cross-validation in hyperparameter tuning?\n",
    "ðŸ‘‰ It ensures the hyperparameters generalize across folds, avoiding overfitting to a single split.\n",
    "\n",
    "**Q4:** Why is Bayesian Optimization preferred in deep learning?\n",
    "ðŸ‘‰ Because it intelligently balances exploration (trying new hyperparameters) and exploitation (refining good ones), reducing training runs.\n",
    "\n",
    "**Q5:** What pitfalls should be avoided in hyperparameter tuning?\n",
    "ðŸ‘‰\n",
    "\n",
    "* Using the test set for tuning (leads to data leakage).\n",
    "* Very large search grids without constraints.\n",
    "* Not fixing random seeds â†’ reproducibility issues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf22d2e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
