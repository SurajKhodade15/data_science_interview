{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ec9ea4",
   "metadata": {},
   "source": [
    "Got it ‚úÖ You mean **Performance Metrics** for ML models.\n",
    "Let‚Äôs build this the same way we did cost functions: structured, interview-style, and practical.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Performance Metrics in Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Regression Metrics**\n",
    "\n",
    "Used when predicting continuous values.\n",
    "\n",
    "### **a) Mean Absolute Error (MAE)**\n",
    "\n",
    "* **Definition:** Average absolute difference between predicted and actual.\n",
    "* **Formula:**\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{n}\\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "* **Interview Insight:** More robust to outliers than MSE.\n",
    "* **Use Case:** Forecasting, finance.\n",
    "\n",
    "---\n",
    "\n",
    "### **b) Mean Squared Error (MSE) & Root Mean Squared Error (RMSE)**\n",
    "\n",
    "* **MSE Formula:**\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "* **RMSE:** Square root of MSE.\n",
    "* **Interview Insight:** RMSE easier to interpret (same unit as target).\n",
    "* **Use Case:** House price prediction.\n",
    "\n",
    "---\n",
    "\n",
    "### **c) R-Squared (Coefficient of Determination)**\n",
    "\n",
    "* **Definition:** Proportion of variance explained by the model.\n",
    "* **Formula:**\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "* **Interpretation:** R¬≤ = 1 ‚Üí perfect fit, R¬≤ = 0 ‚Üí no explanatory power.\n",
    "* **Use Case:** Model goodness-of-fit check.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Classification Metrics**\n",
    "\n",
    "Used when predicting categories.\n",
    "\n",
    "### **a) Accuracy**\n",
    "\n",
    "* **Definition:** Fraction of correctly classified samples.\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "* **Weakness:** Misleading for imbalanced datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### **b) Precision, Recall, F1-Score**\n",
    "\n",
    "* **Precision (Positive Predictive Value):**\n",
    "\n",
    "$$\n",
    "Precision = \\frac{TP}{TP+FP}\n",
    "$$\n",
    "\n",
    "‚ÄúHow many predicted positives are correct?‚Äù\n",
    "\n",
    "* **Recall (Sensitivity, True Positive Rate):**\n",
    "\n",
    "$$\n",
    "Recall = \\frac{TP}{TP+FN}\n",
    "$$\n",
    "\n",
    "‚ÄúHow many actual positives are captured?‚Äù\n",
    "\n",
    "* **F1-Score:** Harmonic mean of precision and recall.\n",
    "\n",
    "$$\n",
    "F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}\n",
    "$$\n",
    "\n",
    "üëâ **Interview Tip:**\n",
    "\n",
    "* Precision focus ‚Üí spam detection.\n",
    "* Recall focus ‚Üí cancer detection.\n",
    "* F1 ‚Üí balance.\n",
    "\n",
    "---\n",
    "\n",
    "### **c) ROC Curve & AUC (Area Under Curve)**\n",
    "\n",
    "* **ROC:** Plots TPR vs FPR at different thresholds.\n",
    "* **AUC:** Area under ROC curve (0.5 random, 1 perfect).\n",
    "* **Use Case:** Model ranking for imbalanced data.\n",
    "\n",
    "---\n",
    "\n",
    "### **d) Log Loss (Cross-Entropy Loss)**\n",
    "\n",
    "* **Formula:**\n",
    "\n",
    "$$\n",
    "LogLoss = -\\frac{1}{n}\\sum [y_i \\log(\\hat{y}_i) + (1-y_i)\\log(1-\\hat{y}_i)]\n",
    "$$\n",
    "\n",
    "* **Use Case:** Probabilistic classifiers.\n",
    "\n",
    "---\n",
    "\n",
    "### **e) Confusion Matrix**\n",
    "\n",
    "* **Definition:** Tabular summary of predictions vs ground truth.\n",
    "* **Example:**\n",
    "\n",
    "```\n",
    "                Predicted\n",
    "               0     1\n",
    "Actual  0    TN    FP\n",
    "        1    FN    TP\n",
    "```\n",
    "\n",
    "* **Interview Insight:** Most metrics derive from this.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Clustering Metrics**\n",
    "\n",
    "Used for unsupervised learning.\n",
    "\n",
    "* **Silhouette Score:** Measures cohesion vs separation (range -1 to 1).\n",
    "* **Adjusted Rand Index (ARI):** Similarity of predicted vs true clusters.\n",
    "* **Davies‚ÄìBouldin Index:** Ratio of intra-cluster distance to inter-cluster separation.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Ranking / Recommendation Metrics**\n",
    "\n",
    "* **Precision\\@K, Recall\\@K:** Evaluate top-K recommendations.\n",
    "* **MAP (Mean Average Precision):** Averages precision across multiple queries.\n",
    "* **NDCG (Normalized Discounted Cumulative Gain):** Rewards ranking order.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚ö° Interview Rapid Fire (Examples)\n",
    "\n",
    "**Q1:** Which metric do you use for regression?\n",
    "üëâ MSE, RMSE, MAE, R¬≤.\n",
    "\n",
    "**Q2:** Your dataset is imbalanced. Is accuracy good?\n",
    "üëâ No. Better use Precision, Recall, F1, AUC.\n",
    "\n",
    "**Q3:** Which metric for recommender system ranking?\n",
    "üëâ Precision\\@K, NDCG.\n",
    "\n",
    "**Q4:** In medical diagnosis, which is more critical ‚Äî Precision or Recall?\n",
    "üëâ Recall (don‚Äôt miss positives).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f57ed32",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
