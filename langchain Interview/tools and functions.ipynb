{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7774c8db",
   "metadata": {},
   "source": [
    "### **Q: Explain tool use & function calling in LangChain with examples.**\n",
    "\n",
    "**Answer:**\n",
    "In LangChain, **tools** and **function calling** extend an LLM beyond its static text-generation capability by allowing it to **interact with external systems** such as APIs, databases, or custom functions.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ **1. Tool Use in LangChain**\n",
    "\n",
    "* **Definition:**\n",
    "  A **tool** is a wrapper around an external capability that the LLM can call during reasoning.\n",
    "* **How it works:**\n",
    "\n",
    "  * Tools are registered in the LangChain framework.\n",
    "  * An **Agent** decides dynamically which tool to call, based on the userâ€™s query.\n",
    "  * The tool executes (e.g., database query, API call) and returns results.\n",
    "* **Example Use Cases:**\n",
    "\n",
    "  * Querying a SQL database.\n",
    "  * Calling a weather API.\n",
    "  * Performing mathematical calculations.\n",
    "\n",
    "**Example (Python):**\n",
    "\n",
    "```python\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Define a simple tool\n",
    "def get_weather(location: str) -> str:\n",
    "    return f\"The weather in {location} is 28Â°C and sunny.\"\n",
    "\n",
    "weather_tool = Tool(\n",
    "    name=\"WeatherTool\",\n",
    "    func=get_weather,\n",
    "    description=\"Get the current weather for a given location\"\n",
    ")\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(\n",
    "    tools=[weather_tool],\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# User query\n",
    "agent.run(\"What is the weather in Pune right now?\")\n",
    "```\n",
    "\n",
    "ðŸ‘‰ Here, the **Agent** interprets the query, calls the `WeatherTool`, and returns the result.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ **2. Function Calling (Structured Tool Use)**\n",
    "\n",
    "* **Definition:**\n",
    "  Function calling is a **structured mechanism** where the LLM doesnâ€™t just generate free text but outputs a **JSON schema** specifying which function to call and with what arguments.\n",
    "* **Why important?**\n",
    "\n",
    "  * Ensures **reliable, structured outputs**.\n",
    "  * Reduces hallucinations when invoking APIs.\n",
    "  * Helps in **safe execution** by validating against predefined schemas.\n",
    "\n",
    "**Example (OpenAI-style function calling in LangChain):**\n",
    "\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-0613\")\n",
    "\n",
    "# Define a tool using decorator\n",
    "@tool\n",
    "def get_stock_price(ticker: str) -> str:\n",
    "    \"\"\"Fetch the latest stock price for a ticker symbol.\"\"\"\n",
    "    return f\"The current stock price of {ticker} is $250.\"\n",
    "\n",
    "# Register tool\n",
    "tools = [get_stock_price]\n",
    "\n",
    "# Function-calling Agent\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "agent = create_openai_functions_agent(llm, tools)\n",
    "\n",
    "# Run query\n",
    "agent.run(\"Get me the latest price of TSLA stock\")\n",
    "```\n",
    "\n",
    "ðŸ‘‰ In this case, the LLM outputs:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"get_stock_price\",\n",
    "  \"arguments\": {\"ticker\": \"TSLA\"}\n",
    "}\n",
    "```\n",
    "\n",
    "LangChain then executes the function and injects the result back into the conversation.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ **Key Difference: Tool Use vs Function Calling**\n",
    "\n",
    "| Aspect      | **Tool Use (Traditional)**         | **Function Calling**                                |\n",
    "| ----------- | ---------------------------------- | --------------------------------------------------- |\n",
    "| Output      | Natural language â†’ parsed by agent | Structured JSON schema                              |\n",
    "| Reliability | Can hallucinate tool names/params  | Safer, validated                                    |\n",
    "| Control     | Less strict, more flexible         | Strict schema enforcement                           |\n",
    "| Use Cases   | General-purpose agents             | Enterprise APIs, DB queries, mission-critical tasks |\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **Closing Note**\n",
    "\n",
    "* **Tool Use** = Give the LLM external powers (like calculators, APIs).\n",
    "* **Function Calling** = A **safer, schema-driven way** for LLMs to call tools without hallucination.\n",
    "* In practice, modern LangChain + OpenAI workflows combine both: **Agents + Tools + Function Calling** to build **robust, enterprise-ready AI assistants**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f35c0ed",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
