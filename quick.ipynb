{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5704833",
   "metadata": {},
   "source": [
    "# ðŸš€ Gen AI / RAG Interview Cheat Sheet â€“ Suraj Khodade\n",
    "\n",
    "| **Category** | **Question** | **One-Line Answer** |\n",
    "|--------------|--------------|----------------------|\n",
    "| **Intro** | Tell me about yourself | 6+ yrs IT (4+ GenAI/NLP) | Built RAG (FAISS/Pinecone) & FastAPI apps; Payroll Assistant cut HR tickets 55%. |\n",
    "| **Gen AI Basics** | What is RAG? | LLM + VectorDB (retrieval+gen) â†’ factual, grounded answers. |\n",
    "| | Why RAG vs fine-tuning? | RAG = flexible, cheaper; FT = domain-locked, costly. |\n",
    "| | How to reduce hallucinations? | Prompt grounding, low temp, reranker, citations, fallback FAQs. |\n",
    "| | What embeddings used? | Sentence-BERT, OpenAI Ada; choice depends on task/domain. |\n",
    "| | Embedding drift handling? | Versioning, re-embed, dual-write, A/B test migration. |\n",
    "| | Hybrid search? | BM25 (keywords) + embeddings â†’ rerank for recall + precision. |\n",
    "| **Vector DBs** | FAISS vs Pinecone vs Weaviate? | FAISS/Chroma: light, local; Pinecone: scalable SaaS; Weaviate: schema, hybrid. |\n",
    "| | How do you choose similarity metric? | Cosine (orientation), Dot (speed/normalized), Euclidean (absolute distance). |\n",
    "| | Why normalize embeddings? | Ensures cosine/dot comparability; avoids magnitude bias. |\n",
    "| **System Design** | How design FastAPI RAG service? | Endpoints (/query,/ingest,/health) | async I/O | Celery+Redis | Docker+K8s | cache. |\n",
    "| | How to scale for 1k users? | Async workers, Redis cache, K8s HPA, fallback models, observability. |\n",
    "| | Handle API rate limits? | Retry/backoff, batching, caching, API Gateway throttling. |\n",
    "| **Quality & Eval** | Key eval metrics? | Precision@k, hallucination rate, latency, adoption %, workload reduction. |\n",
    "| | How to measure success? | Tech (P@k â†‘, hallucinations â†“) â†’ User (40% auto-resolve) â†’ Biz (55% HR tickets â†“). |\n",
    "| | Sustain post-launch? | Auto re-embed, monitor drift, feedback loops, quarterly review. |\n",
    "| **Optimization** | How to cut cost? | Route to smaller models, cache, LoRA, optimized chunking. |\n",
    "| | GPT-4 too costly/slow? | Use GPT-3.5, LLaMA2, Mistral; fallback routing. |\n",
    "| **Security** | Sensitive data handling? | PII masking, RBAC, on-prem/VPC, encrypt at rest+transit, no raw logs. |\n",
    "| **Debug & Test** | Debug inconsistent answers? | Deterministic retriever, low temp, enforce schema, reranker. |\n",
    "| | How to test Gen AI? | Pytest APIs, golden QAs, LangSmith eval, A/B testing. |\n",
    "| **Multimodal** | Extend RAG to images/audio? | Images: CLIP; Audio: Whisper; Video: STT+OCR; Models: GPT-4V, LLaVA. |\n",
    "| | Example: Meeting summarizer? | Whisper STT â†’ chunk/embed â†’ RAG summary â†’ enrich with slides/visuals. |\n",
    "| **Fine-Tuning** | Fine-tuning vs LoRA vs Prompting? | FT: accurate but costly; LoRA: efficient mid-ground; Prompt: cheap, flexible. |\n",
    "| | When to fine-tune? | When domain-specific, repeated tasks not solved by RAG/prompting. |\n",
    "| **Projects** | Payroll Assistant impact? | 40% payroll queries auto-resolved â†’ 55% HR tickets reduced. |\n",
    "| | Recommender impact? | Cosine sim model â†’ staffing efficiency +27%. |\n",
    "| **Behavioral** | Stakeholder resistance? | HR resisted structured data â†’ demoed hybrid solution â†’ dev time â†“25%, efficiency â†‘27%. |\n",
    "| | Explain embeddings to non-tech? | \"Like digital fingerprints of documents\" â†’ similarity = closeness. |\n",
    "| **Learning** | How stay updated? | arXiv | HuggingFace/LangChain | GitHub | LinkedIn | Slack | prototyping. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d916e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
